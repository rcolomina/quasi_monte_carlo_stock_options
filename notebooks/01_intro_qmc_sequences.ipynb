{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Quasi-Monte Carlo Sequences\n",
    "\n",
    "This notebook demonstrates the quasi-random sequence generators implemented in the `qmc_options` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from qmc_options import generators\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Van der Corput Sequence\n",
    "\n",
    "The Van der Corput sequence is a 1-dimensional low-discrepancy sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Van der Corput sequence in base 2\n",
    "N = 100\n",
    "vdc_seq = np.array([generators.van_der_corput(2, i+1) for i in range(N)])\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(vdc_seq, 'o-', markersize=3)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Van der Corput Sequence (base 2)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Halton Sequence\n",
    "\n",
    "The Halton sequence extends Van der Corput to multiple dimensions using different prime bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2D Halton sequence\n",
    "N = 500\n",
    "halton_seq = generators.halton([2, 3], N)\n",
    "\n",
    "# Compare with pure random\n",
    "np.random.seed(42)\n",
    "random_seq = np.random.rand(N, 2)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "ax1.scatter(halton_seq[:, 0], halton_seq[:, 1], s=10, alpha=0.6)\n",
    "ax1.set_title('Halton Sequence (2D)')\n",
    "ax1.set_xlabel('Dimension 1')\n",
    "ax1.set_ylabel('Dimension 2')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.scatter(random_seq[:, 0], random_seq[:, 1], s=10, alpha=0.6)\n",
    "ax2.set_title('Pseudo-Random (2D)')\n",
    "ax2.set_xlabel('Dimension 1')\n",
    "ax2.set_ylabel('Dimension 2')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how Halton points are more uniformly distributed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Lattice Points (GLP)\n",
    "\n",
    "Good Lattice Points use Fibonacci numbers to create highly uniform point sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate GLP with different Fibonacci indices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, m in enumerate([6, 8, 10, 12]):\n",
    "    glp = generators.good_lattice_points(m)\n",
    "    N = len(glp)\n",
    "    \n",
    "    axes[idx].scatter(glp[:, 0], glp[:, 1], s=20, alpha=0.6)\n",
    "    axes[idx].set_title(f'GLP with m={m} (N={N} points)')\n",
    "    axes[idx].set_xlabel('Dimension 1')\n",
    "    axes[idx].set_ylabel('Dimension 2')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Comparison\n",
    "\n",
    "Let's compare how MC and QMC converge for a simple integration problem:\n",
    "$$\\int_0^1 \\int_0^1 x^2 + y^2 \\, dx \\, dy = \\frac{2}{3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(x, y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "# True value\n",
    "true_value = 2/3\n",
    "\n",
    "# Sample sizes to test\n",
    "fib_indices = range(6, 15)\n",
    "errors_glp = []\n",
    "sample_sizes = []\n",
    "\n",
    "for m in fib_indices:\n",
    "    glp = generators.good_lattice_points(m)\n",
    "    N = len(glp)\n",
    "    sample_sizes.append(N)\n",
    "    \n",
    "    # Compute integral\n",
    "    values = test_function(glp[:, 0], glp[:, 1])\n",
    "    estimate = np.mean(values)\n",
    "    error = abs(estimate - true_value)\n",
    "    errors_glp.append(error)\n",
    "\n",
    "# MC comparison\n",
    "errors_mc = []\n",
    "np.random.seed(42)\n",
    "for N in sample_sizes:\n",
    "    mc_points = np.random.rand(N, 2)\n",
    "    values = test_function(mc_points[:, 0], mc_points[:, 1])\n",
    "    estimate = np.mean(values)\n",
    "    error = abs(estimate - true_value)\n",
    "    errors_mc.append(error)\n",
    "\n",
    "# Plot convergence\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.loglog(sample_sizes, errors_glp, 'o-', label='QMC (GLP)', linewidth=2)\n",
    "plt.loglog(sample_sizes, errors_mc, 's-', label='MC (Random)', linewidth=2)\n",
    "\n",
    "# Reference lines\n",
    "N_ref = np.array([sample_sizes[0], sample_sizes[-1]])\n",
    "plt.loglog(N_ref, errors_glp[0] * (N_ref / sample_sizes[0])**(-1), \n",
    "           '--', label='N^(-1)', alpha=0.5)\n",
    "plt.loglog(N_ref, errors_mc[0] * (N_ref / sample_sizes[0])**(-0.5), \n",
    "           '--', label='N^(-0.5)', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Sample Size (N)')\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.title('MC vs QMC Convergence')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"QMC achieves O(N^-1) convergence vs MC's O(N^-0.5)!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
